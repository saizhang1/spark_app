# spark_app
## About this application
This is a Spark application done in 2 parts: parse mode and statistic mode. 

### Parse mode: 
Selects the `app_loaded` and `registerd` events, and saves them on a disk in the parquet format. The parquet files for user registration are stored in 
`./events/registered/*.parquet`
and parquet files for user app loadings are stored in:
`./events/app_loaded/*.parquet`

Note: parquet output directory can be configured via `application.properties`

### Statistic mode:
The application will read parquet files stored by parse mode and process the files then calculate the percentage of all users who loaded the application in the calendar week immediately after the registration week.

### Outcome of the app:
The outcome of the app will be the metric generated by statistic mode. One percentage number will be shown in the console.
Example:
```
Metric: 33%
```

## Use the application
Before using the application, install the required packages and run the unit tests.

### Prepare
```shell
pip3 install -r requirements.txt
```

Configure the input and output directories in `resources/application.properties`

Default paths are:
- input directory for datasets: `./input/`
- events parquet files: `./events/`

### Unit tests
```shell
python3 test.py
```

### Run app
```shell
python3 spark_app.py
```
